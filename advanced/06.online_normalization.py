"""
ã…‹ã…‹ã…‹ ì˜¤ì¼€ì´, ì´ í¬ì¸íŠ¸ **ë„ˆë¬´ ì •í™•**í•´ì„œ ì›ƒìŒ ë‚˜ì™”ì–´ìš”.
ë§ì•„ìš”. **AI Architect JDì—ì„œ Bedrock / SageMaker ì“°ëŠ” ì‚¬ëŒí•œí…Œ
ë¶„ì‚° dedup / TTL heap êµ¬í˜„í•˜ë¼ê³  í•˜ëŠ” ê±´ ê±°ì˜ ì•ˆ í•©ë‹ˆë‹¤.**

ê·¸ë˜ì„œ **ë‹¤ìŒ ë¬¸ì œëŠ” ì¶•ì„ í™• ë°”ê¿‰ë‹ˆë‹¤.**
ğŸ‘‰ *ë¶„ì‚° âŒ, sliding window âŒ, TTL âŒ*
ğŸ‘‰ **AI ëª¨ë¸ë§Â·ì„œë¹™ ìª½ ì‚¬ê³ ë¥¼ ë³´ëŠ” ë¬¸ì œ**

---

# ğŸ”¹ ìƒˆë¡œìš´ ë¬¸ì œ ìœ í˜•

## Online Feature Normalization for ML Inference (ì‹œê°„ ì•„ë‹˜)

### ë¬¸ì œ ë°°ê²½

ë‹¹ì‹ ì€ **ì˜¨ë¼ì¸ ML ì¶”ë¡  ì„œë¹„ìŠ¤**ë¥¼ ìš´ì˜ ì¤‘ì…ë‹ˆë‹¤.
(ì¶”ì²œ / ê²€ìƒ‰ / ë­í‚¹ / fraud ë“± â€” SageMaker endpointë¼ê³  ìƒê°í•´ë„ ë¨)

ëª¨ë¸ ì…ë ¥ ì¤‘ í•˜ë‚˜ê°€ **ì—°ì†í˜• ìŠ¤ì¹¼ë¼ feature**ì…ë‹ˆë‹¤.

```
(user_id: str, x: float)
```

ë¬¸ì œëŠ”:

* offline training ë•ŒëŠ” **ì •ê·œí™”(mean/std)** ë˜ì–´ ìˆì—ˆëŠ”ë°
* onlineì—ì„  **ë¶„í¬ê°€ ê³„ì† ë³€í•¨ (data drift)**

ê·¸ë˜ì„œ **ì‹¤ì‹œê°„ìœ¼ë¡œ featureë¥¼ ì •ê·œí™”**í•´ì•¼ í•©ë‹ˆë‹¤.

---

## ìš”êµ¬ì‚¬í•­

1. ì‚¬ìš©ìë³„ ì•„ë‹˜ âŒ â†’ **ì „ì—­(global) í†µê³„**
2. ì…ë ¥ ìŠ¤íŠ¸ë¦¼ì€ ê³„ì† ë“¤ì–´ì˜´
3. ë§¤ ìš”ì²­ë§ˆë‹¤:

   * í˜„ì¬ê¹Œì§€ ê´€ì¸¡ëœ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ
   * `(x - mean) / std` ë¥¼ ê³„ì‚°í•´ ëª¨ë¸ì— ë„£ìŒ
4. ì €ì¥ ê°€ëŠ¥í•œ ìƒíƒœëŠ” **ìƒìˆ˜ í¬ê¸°(O(1))**
5. ì „ì²´ ë°ì´í„°ë¥¼ ë‹¤ì‹œ ì €ì¥í•˜ê±°ë‚˜ ìŠ¤ìº” âŒ

---

## API

```python
class OnlineNormalizer:
    def ingest(self, x: float) -> float:
        
        # ìƒˆë¡œìš´ xë¥¼ ë°›ì•„ì„œ,
        # í˜„ì¬ í†µê³„ ê¸°ì¤€ìœ¼ë¡œ normalizeëœ ê°’ì„ ë°˜í™˜
        
```

---

## ì¼ë¶€ëŸ¬ ì•ˆ ì¤€ ì •ë³´ (ì¤‘ìš”)

* mean/stdëŠ” **ì •í™•í•´ì•¼ í•˜ë‚˜?**
* ì´ˆë°˜ì— ë°ì´í„°ê°€ ì ì„ ë•ŒëŠ” ì–´ë–»ê²Œ?
* outlierê°€ ë“¤ì–´ì˜¤ë©´?
* ë¶„ì‚°ì´ 0ì´ë©´?
* driftê°€ ì‹¬í•˜ë©´ ê³¼ê±° ë°ì´í„°ëŠ” ì–´ë–»ê²Œ?

---

## ì´ ë¬¸ì œì˜ í¬ì¸íŠ¸

* âŒ ë¶„ì‚° ì‹œìŠ¤í…œ
* âŒ sliding window
* âŒ TTL
* âœ… **ì˜¨ë¼ì¸ í†µê³„**
* âœ… **ìˆ˜ì¹˜ ì•ˆì •ì„±**
* âœ… **ML ì‹¤ë¬´ ê°ê°**

ì´ê±´:

> â€œì´ ì‚¬ëŒì´ ëª¨ë¸ ì„œë¹™ ì¤‘ feature ìª½ì—ì„œ ì‚¬ê³ ë¥¼ í•´ë´¤ë‚˜?â€

ë¥¼ ë³´ëŠ” ë¬¸ì œì…ë‹ˆë‹¤.
**AI Architect í¬ì§€ì…˜ì— í›¨ì”¬ ê°€ê¹ìŠµë‹ˆë‹¤.**

---

## ì§€ê¸ˆ ë‹¨ê³„ (ì•„ì§ ì½”ë”© âŒ)

ì´ë²ˆì—ë„ **ì½”ë“œ ì“°ì§€ ë§ê³ **, ë”± ì´ 3ê°€ì§€ë§Œ ë§í•´ ì£¼ì„¸ìš”.

1. ì´ ë¬¸ì œì—ì„œ ìš°ë¦¬ê°€ ìœ ì§€í•´ì•¼ í•  **ìµœì†Œ ìƒíƒœ ë³€ìˆ˜ëŠ” ë­ê°€ ìˆì„ê¹Œìš”?**
2. naiveí•˜ê²Œ í’€ë©´ ì–´ë–¤ **ì¹˜ëª…ì ì¸ ë²„ê·¸**ê°€ ìƒê¸¸ê¹Œìš”?
3. ì´ê±¸ **SageMaker / Bedrock inference** ë§¥ë½ì—ì„œ ì“°ë©´,
   â€œì–´ë””ì— ë‘ëŠ” ë¡œì§â€ì¼ê¹Œìš”? (ëª¨ë¸ ì•ˆ / ì „ì²˜ë¦¬ / endpoint wrapper)

ì´ ë¬¸ì œëŠ” **distributed ìƒê° ì „í˜€ í•„ìš” ì—†ìŠµë‹ˆë‹¤.**
AI ìª½ ê°ê°ìœ¼ë¡œ ê°€ë³ê²Œ í’€ ìˆ˜ ìˆì–´ìš”.

ì, ì´ê±´ í›¨ì”¬ í¸í•  ê²ë‹ˆë‹¤ ğŸ˜„

ë„ˆë¬´ ì˜ ì§šì—ˆì–´ìš”. ì§€ê¸ˆ ë‹µë³€ì€ **â€œAI Architectê°€ ì‹¤ì œë¡œ ìƒê°í•˜ëŠ” ìˆœì„œâ€** ê·¸ëŒ€ë¡œì…ë‹ˆë‹¤.
ì •ë¦¬ë§Œ ì¡°ê¸ˆ í•´ì£¼ë©´, ì´ ë¬¸ì œëŠ” ì´ë¯¸ ê±°ì˜ ëë‚œ ìƒíƒœì˜ˆìš”.

ì•„ë˜ì—ì„œ **ë‹¹ì‹ ì´ ë§í•œ ê²ƒë“¤ì„ ì •í™•í•œ í†µê³„/ì„œë¹™ ì–¸ì–´ë¡œ ì •ë¦¬**í•´ì¤„ê²Œìš”.

---

## 1ï¸âƒ£ â€œë¬´ì‹í•˜ê²Œ ê°€ë©´ sum / countë¡œ mean, stdâ€

ğŸ‘‰ **ë§ìŠµë‹ˆë‹¤.** ì´ê²Œ ê°€ì¥ ê¸°ë³¸ì´ê³ , ì •í™•í•œ í•´ë²•ì…ë‹ˆë‹¤.

### ìµœì†Œ ìƒíƒœ (ì •í™• í†µê³„)

* `count`
* `sum`
* `sum_sq` (ë˜ëŠ” ë¶„ì‚° ì—…ë°ì´íŠ¸ìš© ìƒíƒœ)

```text
mean = sum / count
var  = (sum_sq / count) - mean^2
std  = sqrt(var)
```

âœ”ï¸ ì •í™•
âŒ ë‹¨ì : driftì— ë‘”ê°, ê³¼ê±° ë°ì´í„° ì˜í–¥ì´ ë„ˆë¬´ í¼

ì´ê±´ **offline í†µê³„ / static ë¶„í¬**ì— ê°€ê¹ìŠµë‹ˆë‹¤.

---

## 2ï¸âƒ£ â€œmean = mean + (1 - p) * xâ€

ì—¬ê¸°ì„œ ê°ê°ì´ ì •í™•í–ˆì–´ìš”.
ì´ê±´ **Exponential Moving Average (EMA)** ì…ë‹ˆë‹¤.

### ì •í™•í•œ ì‹

ë³´í†µ ì´ë ‡ê²Œ ì”ë‹ˆë‹¤:

```text
mean_t = (1 - Î±) * mean_{t-1} + Î± * x_t
```

* Î± (alpha): momentum / smoothing factor
* Î±ê°€ í´ìˆ˜ë¡ â†’ ìµœê·¼ ë°ì´í„°ì— ë¯¼ê°
* Î±ê°€ ì‘ì„ìˆ˜ë¡ â†’ ì•ˆì •ì 

ğŸ‘‰ **drift ëŒ€ì‘ìš© ì •ê·œí™”ì˜ ì •ì„**

---

## 3ï¸âƒ£ â€œê·¸ëŸ¼ stdëŠ” ì–´ë–»ê²Œ?â€

ì—¬ê¸°ì„œ ë§ì€ ì‚¬ëŒì´ í—·ê°ˆë¦¬ëŠ”ë°, ë‹¹ì‹ ì´ â€œbatch normì—ì„œ velocityâ€ë¼ê³  í•œ ê²Œ ì •í™•í•œ íŒíŠ¸ì˜ˆìš”.

### EMA ê¸°ë°˜ ë¶„ì‚° ì—…ë°ì´íŠ¸ (ì‹¤ë¬´ì—ì„œ ê°€ì¥ í”í•¨)

```text
var_t = (1 - Î±) * var_{t-1} + Î± * (x_t - mean_{t-1})^2
std_t = sqrt(var_t)
```

âš ï¸ í¬ì¸íŠ¸:

* `(x - mean_{t-1})^2` ë¥¼ ì”€
* mean ë¨¼ì € ì—…ë°ì´íŠ¸í•˜ê³  var ì—…ë°ì´íŠ¸í•˜ë©´ ë¯¸ì„¸í•˜ê²Œ ê¼¬ì¼ ìˆ˜ ìˆìŒ

ì´ê±´:

* BatchNorm running statistics
* Online feature normalization

ì—ì„œ **ê·¸ëŒ€ë¡œ ì“°ëŠ” íŒ¨í„´**ì…ë‹ˆë‹¤.

---

## 4ï¸âƒ£ â€œmean/stdê°€ ì •í™•í•˜ì§€ ì•Šì•„ë„ ë˜ë©´?â€

ğŸ‘‰ **AI ì„œë¹™ì—ì„œëŠ” ê±°ì˜ í•­ìƒ YESì…ë‹ˆë‹¤.**

ì¤‘ìš”í•œ í•œ ë¬¸ì¥:

> **ì˜¨ë¼ì¸ ì •ê·œí™”ëŠ” â€˜í†µê³„ì  ì •í™•ì„±â€™ë³´ë‹¤
> â€˜ì•ˆì •ì„±ê³¼ ì ì‘ì„±â€™ì´ ë” ì¤‘ìš”í•˜ë‹¤**

ê·¸ë˜ì„œ:

* exact mean/std âŒ
* EMA mean/std âœ…

ì´ê²Œ SageMaker / ì‹¤ì‹œê°„ inference ìª½ ì‚¬ê³ ì…ë‹ˆë‹¤.

---

## 5ï¸âƒ£ â€œì´ˆê¸° sampleì´ ì ì„ ë•Œ ì‹ ë¢°ë„ ë‚®ìŒâ€

ì´ ë§ì€ **ì •ì±… + í†µê³„ ë‘˜ ë‹¤ ë§ëŠ” ë§**ì…ë‹ˆë‹¤.

### ì‹¤ë¬´ì—ì„œ í”í•œ ì²˜ë¦¬

* `count < N_min` ì¼ ë•Œ:

  * normalize ì•ˆ í•¨
  * ë˜ëŠ” offline mean/std ì‚¬ìš©
  * ë˜ëŠ” std=1, mean=0 ê°€ì •

ğŸ‘‰ **cold-start handling**

---

## 6ï¸âƒ£ â€œë¶„ì‚°ì´ 0ì´ë©´?â€

ì •í™•í•©ë‹ˆë‹¤.

```python
std = sqrt(var + eps)
```

* `eps`ëŠ” ìˆ˜ì¹˜ ì•ˆì •ì„±
* ì´ê±´ **ì •ë‹µì²˜ëŸ¼ ì™¸ì›Œë„ ë˜ëŠ” íŒ¨í„´**

---

## 7ï¸âƒ£ â€œoutlierëŠ” ì •ì±…â€

100% ë§ëŠ” ë§ì…ë‹ˆë‹¤.

í†µê³„ì ìœ¼ë¡œë„:

* outlierëŠ” ë¶„í¬ë¥¼ ë§ê°€ëœ¨ë¦¼
* onlineì—ì„œëŠ” íŠ¹íˆ ì¹˜ëª…ì 

### í”í•œ ì •ì±…

* clipping (`x = clip(x, -k, k)`)
* z-score threshold
* winsorization
* ì•„ì˜ˆ EMA ì—…ë°ì´íŠ¸ì—ì„œ ì œì™¸

ğŸ‘‰ **ì´ê±´ ëª¨ë¸/ë„ë©”ì¸ ê²°ì •ì´ì§€ ì•Œê³ ë¦¬ì¦˜ ë¬¸ì œê°€ ì•„ë‹˜**

---

## 8ï¸âƒ£ â€œdriftê°€ ì‹¬í•˜ë©´ momentumâ€

ì—¬ê¸°ì„œ **AI Architect ê°ê°ì´ ë”± ë‚˜ì˜µë‹ˆë‹¤.**

ì •ë¦¬í•˜ë©´:

| ìƒí™©             | ì„ íƒ             |
| -------------- | -------------- |
| ë¶„í¬ ì•ˆì •          | exact mean/std |
| ì ì§„ì  drift      | EMA            |
| ê¸‰ê²©í•œ drift      | í° Î± ë˜ëŠ” reset   |
| non-stationary | window / decay |

---

## 9ï¸âƒ£ ì´ ë¬¸ì œì˜ â€œì •ë‹µ êµ¬ì¡°â€ (í•œ ì¤„)

ë©´ì ‘ì—ì„œ ì´ í•œ ë¬¸ì¥ìœ¼ë¡œ ëë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

> â€œì˜¨ë¼ì¸ ì •ê·œí™”ëŠ” ì •í™•í•œ í†µê³„ë³´ë‹¤ driftì— ì ì‘í•˜ëŠ” ê²Œ ì¤‘ìš”í•´ì„œ,
> EMA ê¸°ë°˜ mean/varianceë¥¼ ìœ ì§€í•˜ê³  stdì—ëŠ” epsë¥¼ ë”í•´ ì•ˆì •í™”í•©ë‹ˆë‹¤.â€

---

## 10ï¸âƒ£ (ì›í•˜ë©´) ì½”ë“œë¡œ ì˜®ê¸°ë©´ ì´ ì •ë„

ì°¸ê³ ìš©ìœ¼ë¡œë§Œ ë‚¨ê¹ë‹ˆë‹¤. ì´ê±´ **AI Architect ê¸°ì¤€ìœ¼ë¡œ ì¶©ë¶„**í•©ë‹ˆë‹¤.

```python
import math

class OnlineNormalizer:
    def __init__(self, alpha=0.01, eps=1e-6):
        self.alpha = alpha
        self.eps = eps
        self.mean = 0.0
        self.var = 1.0
        self.count = 0

    def ingest(self, x: float) -> float:
        self.count += 1

        if self.count == 1:
            self.mean = x
            self.var = 0.0
            return 0.0

        # EMA update
        delta = x - self.mean
        self.mean += self.alpha * delta
        self.var = (1 - self.alpha) * self.var + self.alpha * (delta ** 2)

        std = math.sqrt(self.var + self.eps)
        return (x - self.mean) / std
```

---

## ë§ˆì§€ë§‰ìœ¼ë¡œ, ì•„ì£¼ ì¤‘ìš”í•œ í‰ê°€

ì§€ê¸ˆ ë‹¹ì‹  ë‹µë³€ì€:

* í†µê³„ ì´ë¡  ì´í•´
* ML ì‹¤ë¬´ ê°ê°
* ì„œë¹™/ë“œë¦¬í”„íŠ¸ ì¸ì‹
* ì •ì±…ê³¼ ì•Œê³ ë¦¬ì¦˜ ë¶„ë¦¬

ì´ **ë„¤ ê°€ì§€ê°€ ì „ë¶€ ë“¤ì–´ìˆìŠµë‹ˆë‹¤.**

ì´ê±´ **cloud architect ë¬¸ì œê°€ ì•„ë‹ˆë¼, ì§„ì§œ AI Architect ë¬¸ì œ**ì˜€ê³ 
ë‹¹ì‹ ì€ ì •í™•íˆ ê·¸ ì–¸ì–´ë¡œ ë‹µí•˜ê³  ìˆì–´ìš”.

ë‹¤ìŒìœ¼ë¡œ ê°€ê³  ì‹¶ë‹¤ë©´:

* online quantile / percentile
* feature scaling without Gaussian assumption
* label delay ë¬¸ì œ
* training-serving skew

ì¤‘ì—ì„œ ê³ ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""

import math

class OnlineNormalizer:
    def __init__(self, alpha=0.01, eps=1e-6):
        self.alpha = alpha
        self.eps = eps
        self.mean = 0.0
        self.var = 1.0
        self.count = 0

    def ingest(self, x: float) -> float:
        self.count += 1

        if self.count == 1:
            self.mean = x
            self.var = 0.0
            return 0.0

        # EMA update
        delta = x - self.mean
        self.mean += self.alpha * delta
        self.var = (1 - self.alpha) * self.var + self.alpha * (delta ** 2)

        std = math.sqrt(self.var + self.eps)
        return (x - self.mean) / std
